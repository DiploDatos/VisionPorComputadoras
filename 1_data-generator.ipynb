{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "NUM_CLASSES = 10\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 2018\n",
    "#Model\n",
    "NO_EPOCHS = 50\n",
    "BATCH_SIZE = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar functions\n",
    "def plot_imgs(img_batch):\n",
    "    # Plot the sample images now\n",
    "    f, ax = plt.subplots(4, 4, figsize=(10, 10))\n",
    "    for i, img in enumerate(img_batch):\n",
    "        img = img.reshape(28, 28)\n",
    "        ax[i//4, i%4].imshow(img, cmap='gray')\n",
    "        ax[i//4, i%4].axis('off')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "def data_preprocessing(x_data, y_data):\n",
    "    x_data = x_data.astype('float32')\n",
    "    out_y = to_categorical(y_data, len(np.unique(y_data)))\n",
    "    num_images = x_data.shape[0]\n",
    "    out_x = np.expand_dims(x_data, axis=-1)\n",
    "    \n",
    "    return out_x, out_y\n",
    "\n",
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['acc']\n",
    "    val_acc = hist['val_acc']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    f, ax = plt.subplots(1,2, figsize=(14,6))\n",
    "    ax[0].plot(epochs, acc, 'g', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(epochs, loss, 'g', label='Training loss')\n",
    "    ax[1].plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train_data, y_train_data), (x_test_data, y_test_data) = fashion_mnist.load_data()\n",
    "\n",
    "# prepare the data\n",
    "X, y = data_preprocessing(x_train_data, y_train_data)\n",
    "X_test, y_test = data_preprocessing(x_test_data, y_test_data)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Standardization\n",
    "\n",
    "It is possible to standardize pixel values across the entire dataset. This is called feature standardization and mirrors the type of standardization often performed for each column in a tabular dataset.\n",
    "\n",
    "You can perform feature standardization by setting the `featurewise_center` and `featurewise_std_normalization` arguments on the `ImageDataGenerator` class. These are in fact set to True by default and creating an instance of `ImageDataGenerator` with no arguments will have the same effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(X_train[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=16):\n",
    "    plot_imgs(X_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCA Whitening\n",
    "\n",
    "A whitening transform of an image is a linear algebra operation that reduces the redundancy in the matrix of pixel images.\n",
    "\n",
    "Less redundancy in the image is intended to better highlight the structures and features in the image to the learning algorithm.\n",
    "\n",
    "Typically, image whitening is performed using the Principal Component Analysis (PCA) technique. More recently, an alternative called ZCA [1] shows better results and results in transformed images that keeps all of the original dimensions and unlike PCA, resulting transformed images still look like their originals.\n",
    "\n",
    "You can perform a ZCA whitening transform by setting the zca_whitening argument to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=16):\n",
    "    plot_imgs(X_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Rotations\n",
    "\n",
    "Sometimes images in your sample data may have varying and different rotations in the scene.\n",
    "\n",
    "You can train your model to better handle rotations of images by artificially and randomly rotating images from your dataset during training.\n",
    "\n",
    "The example below creates random rotations of the data up to 90 degrees by setting the rotation_range argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=16):\n",
    "    plot_imgs(X_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Shifts\n",
    "\n",
    "Objects in your images may not be centered in the frame. They may be off-center in a variety of different ways.\n",
    "\n",
    "You can train your deep learning network to expect and currently handle off-center objects by artificially creating shifted versions of your training data. Keras supports separate horizontal and vertical random shifting of training data by the width_shift_range and height_shift_range arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=16):\n",
    "    plot_imgs(X_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Flips\n",
    "\n",
    "Another augmentation to your image data that can improve performance on large and complex problems is to create random flips of images in your training data.\n",
    "\n",
    "Keras supports random flipping along both the vertical and horizontal axes using the vertical_flip and horizontal_flip arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=16):\n",
    "    plot_imgs(X_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a custom preprocessing function\n",
    "\n",
    "You can also add your own preprocessing function.\n",
    "The function should take one argument: one image (Numpy tensor with rank 3, e.g. `shape=(N, M, K)`), and should output a Numpy tensor with the same shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_occlusion(img):\n",
    "    h = IMG_ROWS // 2\n",
    "    w = IMG_COLS // 2\n",
    "    y1 = np.random.randint(h)\n",
    "    y2 = min(y1 + np.random.randint(h), IMG_ROWS)\n",
    "    x1 = np.random.randint(w)\n",
    "    x2 = min(x1 + np.random.randint(w), IMG_COLS)\n",
    "   \n",
    "    img[y1:y2, x1:x2, :] = 0.\n",
    "    \n",
    "    return img\n",
    "\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(preprocessing_function=random_occlusion)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=16):\n",
    "    plot_imgs(X_batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Augmented Images to File\n",
    "\n",
    "The data preparation and augmentation is performed just in time by Keras.\n",
    "\n",
    "This is efficient in terms of memory, but you may require the exact images used during training. For example, perhaps you would like to use them with a different software package later or only generate them once and use them on multiple different deep learning models or configurations.\n",
    "\n",
    "Keras allows you to save the images generated during training. The directory, filename prefix and image file type can be specified to the flow() function before training. Then, during training, the generated images will be written to file.\n",
    "\n",
    "The example below demonstrates this and writes 16 images to a “aug_images” subdirectory with the prefix “aug” and the file type of PNG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, \n",
    "                             height_shift_range=shift,\n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=True)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, \n",
    "                                     batch_size=16, save_to_dir='aug_images', \n",
    "                                     save_prefix='aug', save_format='png'):\n",
    "    plot_imgs(X_batch)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with data augmentation on-the-fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "# Add convolution 2D\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with data augmentation\n",
    "\n",
    "We have to set two `ImageDataGenerator` objects. One for `training` images and another for `validation` images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data generator\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,  # We also can make a rescale on the data\n",
    "    horizontal_flip=True,\n",
    "    rotation_range = 60,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2)\n",
    "\n",
    "# Validation data generator\n",
    "datagen_val = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "# Train!\n",
    "train_model = model.fit_generator(\n",
    "    datagen_train.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "    epochs=NO_EPOCHS,\n",
    "    validation_data=datagen_val.flow(X_val, y_val, batch_size=BATCH_SIZE),\n",
    "    steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
    "    validation_steps=X_val.shape[0] // BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(train_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test / 255., y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Original source: https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "\n",
    "Keras official documentation: https://keras.io/preprocessing/image/#imagedatagenerator-class\n",
    "\n",
    "[1] Learning Multiple Layers of Features from Tiny Images, http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
